## Whole Pipeline

This proposal pipeline follow [Perception architecture discussion](https://github.com/autowarefoundation/autoware/discussions/3).
Based on [the original perception architecture figure](https://github.com/scepter914/autoware-radar-architecture-proposal/blob/main/perception/figure/perception_pipeline_original.drawio.svg) drawn by draw.io, I expand sensor fusion architecture to it for radars.

![The pipeline figure for design document](https://raw.githubusercontent.com/scepter914/autoware-radar-architecture-proposal/main/perception/figure/perception_pipeline.drawio.svg)

This figure put on <https://github.com/scepter914/autoware-radar-architecture-proposal/blob/main/perception/figure/perception_pipeline.drawio.svg>

According to radar output types, I suggest two sensor fusion types in perception module.

- Radar fusion in object layer in tracking module
- Radar fusion in `RadarScan` layer in detection module

## Radar fusion in object layer in tracking module

### Fusion tracking

In fusion tracking, radar tracked objects are fused for other tracked objects in tracking module.
As discussed in [Perception architecture discussion](https://github.com/autowarefoundation/autoware/discussions/3), fusion tracking module handles tracked objects as below.

- Detected 3d objects from Camera-LiDAR-Radar fusion
- LiDAR tracked 3d objects
- Camera tracked 3d objects
- Radar tracked 3d objects

### Radar detection and tracking

The tracked radar objects have the following features and can use for fusion tracking.

- Far (> 100m) objects recognition
- More precise twist information estimated by doppler velocity
- Low accuracy of position and size information

Radar tracked objects are generated by two types.

![The pipeline figure for design document](https://raw.githubusercontent.com/scepter914/autoware-radar-architecture-proposal/main/perception/figure/radar_detection_tracking.drawio.svg)

- Radar driver

If you have radar driver which can publish `ros-perception/radar_msgs/msg/RadarTrack.msg`, tracked objects calculated inside the radar devices, then you can enter radar outputs to fusion tracking.
Using the converter from from `ros-perception/radar_msgs/msg/RadarTrack.msg` to `autoware_auto_perception_msgs/msg/TrackedObject`, you can connect to fusion tracking.
The radars which can output tracked objects can make sensor fusion pipeline simpler with few parameters.

- Radar 3d clustering and tracking

If you have radar driver which publish `ros-perception/radar_msgs/msg/RadarScan`, then you can use radar 3d clustering and tracking module.
The module clusters dynamic `RadarScan` to recognize dynamic objects and tracks using doppler velocity.

## Sensor fusion with `RadarScan` in detection module

In addition to Camera-LiDAR sensor fusion in detection layer is proposed in [Perception architecture discussion](https://github.com/autowarefoundation/autoware/discussions/3), I suggest Camera-LiDAR-Radar sensor fusion in detection layer.

### Camera-LiDAR-Radar 3d detection using multiple modules

Camera-LiDAR-Radar 3d detection consists of two state sensor fusion.

- Camera-LiDAR fusion

First state is camera-LiDAR fusion.
Camera-LiDAR fusion packages aim to improve class label accuracy.
Detected 2d objects and detected 3d objects are fused in camera-LiDAR Fusion like [roi_cluster_fusion](https://github.com/autowarefoundation/autoware.universe/tree/main/perception/roi_cluster_fusion) and [image_projection_based_fusion in the future](https://github.com/autowarefoundation/autoware.universe/pull/548).

- Radar fusion

First state is radar fusion.
After camera-LiDAR fusion, detected 3d objects from camera-LiDAR fusion and  `RadarScan` are fused in radar fusion modules.

Radar fusion packages aim to improve detection performance using detected 3d objects with low confidence and `RadarScan`.
Radar fusion packages attach doppler velocity from `RadarScan` for detected 3d objects to improve velocity estimation in tracking module.

By defining `DetectedObjects` as the input interface for camera and LiDAR data, it can improve usability for sensor fusion architecture; For example, radar fusion module can be applied to camera 3d detection.
